# Atelier Data Science Responsable et de Confiance #4 | 23 Juin 2020 à 14h

Dépôt du projet : [https://github.com/SubstraFoundation/referentiel-ds-responsable-confiance](https://github.com/SubstraFoundation/referentiel-ds-responsable-confiance)

Participants : *Céline Jacques, Amine Saboni, Jeremie Abiteboul, Annabelle Blangero, Anne-Sophie Cissey, Cedric Meurée, Elmahdi Kardaoui, Eric Dubois, Anasse Berahab, Jean Haizmann , Sophie Lohézic, Vincent Quiblier, Nicolas Siami, Marie Lange, Soumia Ghalim, Timothé Faucon, Eric Boniface, Clément Mayer, Nicolas Landel, Nathanaël Cretin, Fabien Gelus, Romain Goussault*

# Evolutions du référentiel depuis l'atelier #3

- Retours de Cédric (AiVision)
- Refonte de la forme
- Nouveaux éléments d'évaluation (question de la répartition création de valeur \& transparence quant à l'utilisation de modèles prédictifs)
- Nouveaux items de réponse, rédaction
- Nouvelles ressources et références !
- Démarrage de la traduction du référentiel en anglais

## Retours d'expérience

### Retour d'expérience de Jérémie Abiteboul (DreamQuark)

- Fintech (outil utilise ML pour banques) mais utilisateurs produits (pas de connaissances en ML)
- logiciel (cas d'usage de recommandation produit, attrition) -> responsable et de confiance gd enjeux car DreamQuark doit garantir confiance
- Expérience :
  - 45 minutes pour première session
  - 1 à 2h en plus pour **confirmer certaines réponses** (DPO \& contractuel)
  - Difficulté : "produit vs projet" (!) (l'outil permet à l'utilisateur de déployer des algos). Idée : mettre en place une charte pour les utilisateurs du produit
  - Good : validation des perf, explicabilité, monitoring, généalogie (rapport de modèle complet, annotable par l'utilisateur)
  - domaine de validité -> point plus précis que leur orga
  - Pourrait mieux faire : veille \& documentation
  - Reste à améliorer (pas pensé ou pas eu le temps de s'y pencher) : ML sec, Biais / métrique de Fairness), chaine de responsabilité (pas directement concerné mais question reste pertinente), impact CO2, impact éthique (pensé mais pas formalisé)

Fonctionnalités de Dream Quark:

- volonté de transparence des seuils auprès des clients
- génénalogie : rapport du modèle fourni auprès des clients (performances, type de modèle)+versioning
  - -> pas d'info sur la répartition des data training/test fournie auprès des users -> besoin des utilisateurs et en cours de dev
- monitoring stabilité des données: en production warnings lorsque feature sort du domaine de validité
- monitoring stabilité du score / à entraînement (est ce que comportements clients ont changé ? est ce que en dehors du domaine de validité ? )    

### Retour d'expérience de Céline Jacques (Apricity)

- 2h+ pour faire l'évaluation, le temps de bien parcourir tous les éléments
- prise de notes de sa part pour chaque éléments d'évaluation
- palette de choix trop "manichéenne" 
- manquerait une synthèse par section (-> champs Notes !)

### Merci également à Cédric Meurée (Aivision) pour son 2nd retour sur le référentiel

## Présentation du modèle de *scoring*

But du scoring : avoir un point de repère par rapport à d'autres orga ou dans le temps

Score additif simple (sur 100) ; référence à Bcorp (score sur 200 [https://bcorporation.net/)](https://bcorporation.net/)) \& coeff. Prise en compte des éléments non pertinents pour une organisation (complexité à recouvrir tous les cas d'usages/types de structure)    
=> Règle d'équilibrage : 50% des points attribués automatiquement (cf potentiels non accessibles/non concerné) \& dilatation des points des autres éléments d'évaluation, jusqu'à un total de 100. Objectif de positionnerait relatif

Suggestion de Fabien : Ajouter un 2e score de risque en complément au 1er score d'éval

Question d'Amine Saboni : "Plutôt que de réduire le score total, est ce que présenter les résultats dans le scope des questions répondues ne serait pas mieux ?"

-> oui c'est un peu ce qu'on fait déjà, si on peut répondre à 90% du score, 10% du score manquant -> 5 points attribués automatiquement + une dilatation du score (qui est sur 95) pour le ramener sur 100

Idée de faire un score par section (pb si trop de parties non concernées dans une section ?)

Suggestion de Sophie Lohézic :

"Bonjour. ce serait peut-être intéressant dans tous les cas d'avoir le score sur les sous-thèmes : EDP : l'Exposition de Données Personnelles ou confidentielles PDI : la Prise de Décisions Inappropriées par des systèmes automatiques RC : ne pas Rendre des Comptes de manière responsable à ses parties prenantes ESE : avoir une Empreinte Sociale et Environnementale irresponsable TR : transverses

Pour ensuite avoir des recommandations "d'amélioration"

=> scores par question

=> ressources qui permettent de fournir pistes d'améliorations

## Développement de la plateforme d'autoévaluation

Principales fonctionnalités => faire son évaluation, prendre des notes, obtenir un score \& une évaluation, inscrire son organisation et pouvoir comparer des résultats (dans le temps et entre différents organisations/départements)

Centre de ressources / bonnes pratiques dsrc

Présentation de la plateforme :

- page d'acceuil
- versionning du référentiel et des évaluations
- vue grid des sections
- liste des questions par section
- choix multiples / simple
- champ prise de note (non pris en compte pour l'évaluation, mais permet de garder des éléments au sein d'une organisation)
- vue résultats en cours de finalisation (cf scoring en cours d'élaboration)

Question d'Amine : forme de la page de résultat (dataviz, texte) ?

=> Les deux + format détachable + format type certification  : objectif d'avoir un document que l'on puisse fournir aux clients de l'entreprise, comme justificatif des bonnes pratiques 

## Certification

Evaluation *open access*

- Légitimité de la certif vis à vis des partenaires
- Labelisation (certification de l'auto-évaluation)
- Ressources techniques
- Réseau de partenaires experts
- question d'Annabelle Blangero : "certification à la B-corp"

=> yea, it's so cool!

Cf. leur nested questions?

=> Yes, cf. affichage conditionnel des questions

Question de Timothé Faucon : durée de validité de la certif ?

Cf. bonnes pratiques de l'audit, donc oui, ex. Bcorp = 3 ans

Les pratiques et les exigences évoluent.

Question d'Annabelle Blangero : AO du gouvernement pour la certification ?

Cf. Mission parlementaire sur la filière IA (?)

-> "défis IA"

A voir si contexte de l'AO assez globale pour rentrer dans les critères

Question de Timothé Faucon : y a-t-il un risque de conflit d'intérêt de l'organisme certificateur ?

- tjs ce pb pour les certifications : il ne faut pas que ça soit trop simple car sinon plus de valeurs et désintérêt de la part des utilisateurs

Vivement le prochain atelier *irl*
s