# Atelier DSRC #6 du 10 novembre 2020

Présents : *@ClementMayer, @bowni, @natct10, @nicolas-landel, @celinejacques, @cmeuree, @RomainGoussault, @Fabien-GELUS, @arthurPignet, Mickaël Fine, Nathan L., Daniel Bartolo, Théo L., Joséphine Lecoq-Vallon, Patricia L, Chloé, Ana Ulianovici, Eric Armbruster, Ali T, Victoire M, Paul-Marie C, Cécile G, Arnaud L*
​
## Liens utiles 

- [Dépot du projet](https://github.com/SubstraFoundation/referentiel-evaluation-dsrc)
- [Références](https://github.com/SubstraFoundation/referentiel-evaluation-dsrc/blob/master/references.md)
- [Evaluation](https://github.com/SubstraFoundation/referentiel-evaluation-dsrc/blob/master/referentiel_evaluation.md)
- [site internet](https://www.substra.ai/)
- [Article de blog](https://www.substra.ai/fr/blog/evaluation-data-science-responsable)
- [Substra Slack, salon DSRC](https://substra-workspace.slack.com/archives/CTQ1SNPK2)

## Compte-rendu de l'atelier

### Actualités

- Préparation de matériaux pédagogiques dans le cadre de la saison 8 de Data For Good (notebooks sur les fairness metrics, robustesse de modèle, DP, distilation de modèle, généalogie modèle de bout-en-bout)
- Retour sur les dernières actualités et événements de Substra Foundation
- Livre blanc ImpactAI (en préparation pour le 10 Décembre) : Guide pratique pour l'IA digne de confiance
- Syntec Numérique : "Concevoir des IA éthiques by design" (6 ateliers jusqu'à Noël)

### Evolutions du référentiel

- Stabilisation du référentiel par rapport aux premières versions
- Découpage en 6 sections désormais, affinage de l'évaluation globale et travail de reformulation/clarification
- _En cours_ Prise en compte du secteur publique et de ses spécificités
- Ajouts de nouvelles ressources : 

    - [Privacy Enhancing Technologies Decision Tree (v2)](https://private-ai.ca/PETs_Decision_Tree.png)
    - [Faulty Facial Recognition Led to His Arrest—Now He’s Suing](https://www.vice.com/en/article/bv8k8a/faulty-facial-recognition-led-to-his-arrestnow-hes-suing)
    - [Stratified cross-validation for unbiased and privacy-preserving federated learning](https://arxiv.org/abs/2001.08090)
    - Model Cards : 

        - [Model Cards for Model Reporting](https://arxiv.org/abs/1810.03993)
    - Méta-étude : 

        - [A Unified Framework of Five Principles for AI in Society](https://hdsr.mitpress.mit.edu/pub/l0jsh9d1/release/6)
    - Fairness metrics : 

        - [Unfair biases in Machine Learning: what, why, where and how to obliterate them](https://www.mlsecurity.ai/post/unfair-biases-in-machine-learning-what-why-where-and-how-to-obliterate-them)
        - [A Tutorial on Fairness in Machine Learning](https://towardsdatascience.com/a-tutorial-on-fairness-in-machine-learning-3ff8ba1040cb)
        - [Fairness and machine learning - Limitations and opportunities](https://fairmlbook.org/)

### Lancement version beta de la plateforme d’évaluation

- Présentation des fonctionalités de l'auto-évaluation : création de comptes et des organisations, gestion des ressources, scoring, feedback...
- Lancement probable le 17 novembre 2020 !
- Accès à la plateforme : [https://assessment.substra.ai/](https://assessment.substra.ai/)

Question : 

    - explication du scoring ? --> Une explication sera ajoutée sur la plateforme - travail en cours côté Substra
    - Mise à jour du référentieel ? --> Objectif de stabilité du référentiel, avec évolution tous les 3 à 6 mois 

### Data For Good (S08) - Axes de travail

#### Généalogie de bout-en-bout

- Présentation du [template](https://github.com/dataforgoodfr/batch8_substra/blob/master/G%C3%A9n%C3%A9alogie%20de%20bout-en-bout/Genealogie-de-bout-en-bout_template.md) en cours de constitution par Joséphine. 
- Objectif : proposer un document de référence sur la production d'un modèle, ex. Google Cards Face detection et construction d'un template à usage des data scientists

#### Distillation de modèles 

- Travaux en cours sur des librairies de distillation de modèle.
- Objectif : proposer un  notebook utilisable par des data scientists 

#### Robustness metrics 

- Travaux en cours sur les robustness metrics, au delà de l'overfitting. 
- Objectif : proposer un notebook utilisable par des data scientists 
